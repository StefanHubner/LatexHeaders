Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@incollection{McFadden1974,
author = {McFadden, Daniel},
doi = {10.1080/07373937.2014.997882},
file = {:home/stefan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/McFadden - 1974 - Conditional Logit Analysis of Qualitative Choice Behavior.pdf:pdf},
issn = {15322300},
pages = {105--142},
title = {{Conditional Logit Analysis of Qualitative Choice Behavior}},
year = {1974}
}
@article{Abbring2007,
abstract = {This chapter develops three topics. (1) Identification of the distributions of treatment effects and the distributions of agent subjective evaluations of treatment effects. Methods for identifying ex ante and ex post distributions are presented and empirical examples are given. (2) Identification of dynamic treatment effects. The relationship between the statistical literature on dynamic causal inference based on sequential-randomization and the dynamic discrete-choice literature is exposited. The value of well posed economic choice models for decision making under uncertainty in analyzing and interpreting dynamic intervention studies is developed. A survey of the dynamic discrete-choice literature is presented. (3) The key ideas and papers in the recent literature on general equilibrium evaluations of social programs are summarized. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Abbring, Jaap H. and Heckman, James J.},
doi = {10.1016/S1573-4412(07)06072-2},
file = {:home/stefan/Dropbox/Academia/Library/Abbring, Heckman{\_}2007{\_}Econometric Evaluation of Social Programs, Part III Distributional Treatment Effects, Dynamic Treatment Effects, D.pdf:pdf},
isbn = {9780444532008},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {distributions of treatment effects,dynamic discrete choice,dynamic treatment effects,general equilibrium policy evaluation},
number = {SUPPL. PART B},
pages = {5145--5303},
title = {{Econometric Evaluation of Social Programs, Part III: Distributional Treatment Effects, Dynamic Treatment Effects, Dynamic Discrete Choice, and General Equilibrium Policy Evaluation}},
volume = {6},
year = {2007}
}
@article{Phillips1983,
author = {Phillips, P C B},
file = {:home/stefan/Dropbox/Academia/Library/Phillips{\_}1983{\_}Exact Small Sample Theory in Simultaneous Equations.pdf:pdf},
journal = {Handbook of Econometrics},
title = {{Exact Small Sample Theory in Simultaneous Equations}},
volume = {I},
year = {1983}
}
@article{Engle1984,
author = {Engle, Robert F},
file = {:home/stefan/Dropbox/Academia/Library/Engle{\_}1984{\_}Wald, likelihood ratio, and lagrange multiplier tests in econometrics BT - Handbook of Econometrics.pdf:pdf},
journal = {Handbook of Econometrics},
number = {13},
pages = {1--52},
title = {{Wald, likelihood ratio, and lagrange multiplier tests in econometrics BT  - Handbook of Econometrics}},
url = {papers3://publication/uuid/A665BDFB-8278-46AC-81CC-74AF7E2F5CFE},
volume = {2},
year = {1984}
}
@article{Leamer2007,
abstract = {The greatest problem for empirical analysis is how best to allow the context to affect the inferences. Econometric theory presupposes contextual "restrictions" that can be taken as given or assigned a probability distribution. These contextual inputs are rarely available. I illustrate this point with a review of the empirical work in international economics which has focused not on properties of estimators but instead how best to link the theory with the data. I argue that the two errors we should worry about are not rejecting a true null or accepting a false null but rather taking the theory too seriously and not taking the theory seriously enough. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Leamer, Edward E.},
doi = {10.1016/S1573-4412(07)06067-9},
file = {:home/stefan/Dropbox/Academia/Library/Leamer{\_}2007{\_}Linking the Theory with the Data That is the Core Problem of International Economics.pdf:pdf},
isbn = {9780444506313},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {Heckscher-Ohlin theory,Leontief paradox,hypothesis testing,usefulness or truthfulness},
number = {SUPPL. PART A},
pages = {4587--4606},
title = {{Linking the Theory with the Data: That is the Core Problem of International Economics}},
volume = {6},
year = {2007}
}
@article{Agung2010,
author = {Bollerslev, Tim and Engle, Robert F. and Nelson, Daniel B.},
doi = {10.1002/9780470823699.ch8},
file = {:home/stefan/Dropbox/Academia/Library/Bollerslev, Engle, Nelson{\_}1994{\_}ARCH Models.pdf:pdf},
journal = {Handbook of Econometrics},
title = {{ARCH Models}},
year = {1994}
}
@article{Watson1984,
author = {Granger, Clive W.J. and Watson, Mark W.},
file = {:home/stefan/Dropbox/Academia/Library/Granger, Watson{\_}1984{\_}Time Series and Spectral Methods in Econometrics.pdf:pdf},
journal = {Handbook of Econometrics},
title = {{Time Series and Spectral Methods in Econometrics}},
url = {http://www.ses.wsu.edu/people/faculty/LaFrance/Courses/EconS514/Handbook-of-Econometrics/Volume-2/Granger-hoe-1984.pdf},
volume = {II},
year = {1984}
}
@article{Ackerberg2007,
abstract = {This paper outlines recently developed techniques for estimating the primitives needed to empirically analyze equilibrium interactions and their implications in oligopolistic markets. It is divided into an introduction and three sections; a section on estimating demand functions, a section on estimating production functions, and a section on estimating "dynamic" parameters (parameters estimated through their implications on the choice of controls which determine the distribution of future profits). The introduction provides an overview of how these primitives are used in typical I.O. applications, and explains how the individual sections are structured. The topics of the three sections have all been addressed in prior literature. Consequently each section begins with a review of the problems I.O. researchers encountered in using the prior approaches. The sections then continue with a fairly detailed explanation of the recent techniques and their relationship to the problems with the prior approaches. Hopefully the detail is rich enough to enable the reader to actually program up a version of the techniques and use them to analyze data. We conclude each section with a brief discussion of some of the problems with the more recent techniques. Here the emphasis is on when those problems are likely to be particularly important, and on recent research designed to overcome them when they are. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Ackerberg, Daniel and {Lanier Benkard}, C. and Berry, Steven and Pakes, Ariel},
doi = {10.1016/S1573-4412(07)06063-1},
file = {:home/stefan/Dropbox/Academia/Library/Ackerberg et al.{\_}2007{\_}Econometric Tools for Analyzing Market Outcomes.pdf:pdf},
isbn = {9780444506313},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {demand estimation,dynamic estimation,equilibrium outcomes,production function estimation,strategic interactions},
number = {SUPPL. PART A},
pages = {4171--4276},
title = {{Econometric Tools for Analyzing Market Outcomes}},
volume = {6},
year = {2007}
}
@article{Blundell2007,
abstract = {This chapter is concerned with the identification and estimation of models of labor supply. The focus is on the key issues that arise from unobserved heterogeneity, nonparticipation and dynamics. We examine the simple "static" labor supply model with proportional taxes and highlight the problems surrounding nonparticipation and missing wages. The difference-in-differences approach to estimation and identification is developed within the context of the labor supply model. We also consider the impact of incorporating nonlinear taxation and welfare program participation. Family labor supply is looked at from both the unitary and collective perspectives. Finally we consider intertemporal models focusing on the difficulties that arise with participation and heterogeneity. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Blundell, Richard and MaCurdy, Thomas and Meghir, Costas},
doi = {10.1016/S1573-4412(07)06069-2},
file = {:home/stefan/Dropbox/Academia/Library/Blundell, MaCurdy, Meghir{\_}2007{\_}Labor Supply Models Unobserved Heterogeneity, Nonparticipation and Dynamics.pdf:pdf},
isbn = {9780444506313},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {consumption,labor supply,microeconometrics,taxation},
number = {SUPPL. PART A},
pages = {4667--4775},
title = {{Labor Supply Models: Unobserved Heterogeneity, Nonparticipation and Dynamics}},
volume = {6},
year = {2007}
}
@article{Diewert2007,
abstract = {This chapter covers the theory and methods for productivity measurement for nations. Labor, multifactor and total factor productivity measures are defined and are related to each other and to gross domestic product (GDP) per capita. Their growth over time and relative counterparts are defined as well. Different conceptual meanings have been proposed for a total factor productivity growth (TFPG) index. These are easiest to understand for the case in which the index number problem is absent: a production process that involves one input and one output (a 1-1 process). It is easily seen that four common concepts of TFPG all lead to the same result in the 1-1 case. Moving on to a general N input, M output production scenario, we demonstrate that a Paasche, Laspeyres or Fisher index number formula provides a measure for all four of the concepts of TFPG introduced for the 1-1 case. This is an advantage of the Paasche-Laspeyres-Fisher family of formulas. When multiple inputs or outputs are involved, there is the problem of choosing among alternative functional forms. The axiomatic and economic approaches to index formula choice are reviewed. In addition, we briefly cover the Divisia index number approach and growth accounting, including the KLEMS (capital, labor, energy, materials and services) approach. The gross output measures of the KLEMS approach are contrasted with value added output measures such as GDP. Also, an alternative family of revenue function based productivity growth indexes proposed by Diewert, Kohli and Morrison (DKM) is outlined. The DKM approach facilitates the decomposition of productivity growth into economically meaningful components. This approach is useful, for example, for examining the effects of changes in the terms of trade on productivity growth. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Diewert, W. Erwin and Nakamura, Alice O.},
doi = {10.1016/S1573-4412(07)06066-7},
file = {:home/stefan/Dropbox/Academia/Library/Diewert, Nakamura{\_}2007{\_}The Measurement of Productivity for Nations.pdf:pdf},
isbn = {9780444506313},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {KLEMS,aggregation of capital,capital deepening,depreciation,deterioration,embodiment of technical progress,exact index numbers,gross versus net output,growth accounting,index number theory,labor productivity,living standards,obsolescence,real income growth,terms of trade,total factor productivity growth},
number = {SUPPL. PART A},
pages = {4501--4586},
title = {{The Measurement of Productivity for Nations}},
volume = {6},
year = {2007}
}
@article{Bergvanden2001,
abstract = {Since the early 1980s, the econometric analysis of duration variables has become widespread. This chapter provides an overview of duration analysis, with an emphasis on the specification and identification of duration models, and with special attention to models for multiple durations. Most of the chapter deals with so-called reduced-form duration models, notably the popular Mixed Proportional Hazard (MPH) model and its multivariate extensions. The MPH model is often used to describe the relation between the empirical exit rate and "background variables[equals, rising dots] in a concise way. However, since the applications usually interpret the results in terms of some economic-theoretical model, we examine to what extent the deep structural parameters of some important theoretical models can be related to reduced-form parameters. We subsequently examine the specification and identification of the MPH model in great detail, we provide intuition on what drives identification, and we infer to what extent biases may occur because of misspecifications. This examination is carried out separately for the case of single-spell data and the case of multi-spell data. We also compare different functional forms for the unobserved heterogeneity distribution. Next, we examine models for multiple durations. In the applied econometric literature on the estimation of multiple-duration models, the range of different models is actually not very large. Typically, the models allow for dependence between the duration variables by way of their unobserved determinants, with each single duration following its own MPH model. In addition to this, the model may allow for an interesting "causal[equals, rising dots] effect of one duration on the other, as motivated by an underlying economic theory. For all these models we examine the conditions for identification. Some of these are intimately linked to particular estimation strategies. The multiple-duration model where the marginal duration distributions each satisfy an MPH specification, and the durations can only be dependent by way of their unobserved determinants, is called the Multivariate Mixed Proportional Hazard (MMPH) model. For this model, we address the issue of the dimensionality of the heterogeneity distribution and we compare the flexibility of different parametric heterogeneity distributions. On a number of occasions, we incorporate recent insights from the biostatistical literature on duration analysis, and we contrast points of view in this literature to those in the econometric literature. Finally, throughout the chapter, we discuss the importance of the possible collection of additional data.},
author = {Berg van den, G J},
file = {:home/stefan/Dropbox/Academia/Library/Berg van den{\_}2001{\_}Duration models specification, identification and multiple durations.pdf:pdf},
isbn = {1573-4412},
journal = {Handbook of Econometrics},
keywords = {duration analysis,duration dependence,duration model,failure rate,failure time,hazard function,hazard rate,identification,multiple spells,proportional hazard,shocks,transition rate,treatment effect,unemployment duration,unobserved heterogeneity},
pages = {3381--3460},
title = {{Duration models: specification, identification and multiple durations}},
url = {http://www.sciencedirect.com/science/article/B7GX7-4DXJCWR-1G/2/50f0060fe9d7ea8fd19278b0df0653d8},
volume = {5},
year = {2001}
}
@article{Deaton1986,
author = {Deaton, Angus},
doi = {10.1016/S1573-4412(86)03010-6},
file = {:home/stefan/Dropbox/Academia/Library/Deaton{\_}1986{\_}Demand analysis.pdf:pdf},
issn = {15734412},
journal = {Handbook of Econometrics},
pages = {1767--1839},
title = {{Demand analysis}},
volume = {3},
year = {1986}
}
@article{Matzkin1994,
author = {Matzkin, Rosa},
file = {:home/stefan/Dropbox/Academia/Library/Matzkin{\_}1994{\_}Restriction of Economic Theory in Nonparametric Methods.pdf:pdf},
journal = {Handbook of Econometrics},
pages = {2523--2558},
title = {{Restriction of Economic Theory in Nonparametric Methods}},
volume = {4},
year = {1994}
}
@book{Katz2014,
author = {Hsiao, Cheng},
booktitle = {Handbook of Econometrics},
doi = {10.5005/jp/books/12576_4},
file = {:home/stefan/Dropbox/Academia/Library/Hsiao{\_}1983{\_}Identification.pdf:pdf},
isbn = {9781135221850},
issn = {0032-633X},
title = {{Identification}},
year = {1983}
}
@article{Carrasco2007,
abstract = {Inverse problems can be described as functional equations where the value of the function is known or easily estimable but the argument is unknown. Many problems in econometrics can be stated in the form of inverse problems where the argument itself is a function. For example, consider a nonlinear regression where the functional form is the object of interest. One can readily estimate the conditional expectation of the dependent variable given a vector of instruments. From this estimate, one would like to recover the unknown functional form. This chapter provides an introduction to the estimation of the solution to inverse problems. It focuses mainly on integral equations of the first kind. Solving these equations is particularly challenging as the solution does not necessarily exist, may not be unique, and is not continuous. As a result, a regularized (or smoothed) solution needs to be implemented. We review different regularization methods and study the properties of the estimator. Integral equations of the first kind appear, for example, in the generalized method of moments when the number of moment conditions is infinite, and in the nonparametric estimation of instrumental variable regressions. In the last section of this chapter, we investigate integral equations of the second kind, whose solutions may not be unique but are continuous. Such equations arise when additive models and measurement error models are estimated nonparametrically. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Carrasco, Marine and Florens, Jean Pierre and Renault, Eric},
doi = {10.1016/S1573-4412(07)06077-1},
file = {:home/stefan/Dropbox/Academia/Library/Carrasco, Florens, Renault{\_}2007{\_}Linear Inverse Problems in Structural Econometrics Estimation Based on Spectral Decomposition and Regula.pdf:pdf},
isbn = {9780444532008},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {Tikhonov and Landweber-Fridman regularizations,additive models,generalized method of moments,instrumental variables,integral equation,many regressors,nonparametric estimation},
number = {SUPPL. PART B},
pages = {5633--5751},
title = {{Linear Inverse Problems in Structural Econometrics Estimation Based on Spectral Decomposition and Regularization}},
volume = {6},
year = {2007}
}
@book{Zellner1983,
author = {Zellner, Arnold},
booktitle = {Handbook of Econometrics},
file = {:home/stefan/Dropbox/Academia/Library/Zellner{\_}1983{\_}Statistical Theory and econometrics.pdf:pdf},
title = {{Statistical Theory and econometrics}},
volume = {I},
year = {1983}
}
@article{Hendry1984a,
author = {Hendry, David F and Sargan, Denis J and Pagan, Adrian R.},
file = {:home/stefan/Dropbox/Academia/Library/Hendry, Sargan, Pagan{\_}1984{\_}DYNAMIC SPECIFICATION Data generation processes Stochastic specification Dynamic specification in multi-equat.pdf:pdf},
journal = {Handbook of Econometrics},
title = {{DYNAMIC SPECIFICATION Data generation processes Stochastic specification Dynamic specification in multi-equation models References}},
volume = {II},
year = {1984}
}
@article{Manski1994,
author = {Manski, Charles F.},
file = {:home/stefan/Dropbox/Academia/Library/Manski{\_}1994{\_}Analog estimation of econometrics models.pdf:pdf},
journal = {Handbook of Econometrics},
pages = {2559--2582},
title = {{Analog estimation of econometrics models}},
volume = {IV},
year = {1994}
}
@article{Dhrymes1986,
author = {Dhrymes, Phoebus J},
file = {:home/stefan/Dropbox/Academia/Library/Dhrymes{\_}1986{\_}Limited Dependent Variables.pdf:pdf},
journal = {Handbook of Econometrics},
pages = {1567--1631},
title = {{Limited Dependent Variables}},
url = {http://www.ses.wsu.edu/people/faculty/LaFrance/Courses/EconS514/Handbook-of-Econometrics/Volume-3/Dhrymes-hoe-1986.pdf},
volume = {3},
year = {1986}
}
@article{Matzkin2007a,
abstract = {When one wants to estimate a model without specifying the functions and distributions parametrically, or when one wants to analyze the identification of a model independently of any particular parametric specification, it is useful to perform a nonparametric analysis of identification. This chapter presents some of the recent results on the identification of nonparametric econometric models. It considers identification in models that are additive in unobservable random terms and in models that are nonadditive in unobservable random terms. Single equation models as well as models with a system of equations are studied. Among the latter, special attention is given to structural models whose reduced forms are triangular in the unobservable random terms, and to simultaneous equations, where the reduced forms are functions of all the unobservable variables in the system. The chapter first presents some general identification results for single-equation models that are additive in unobservable random terms, single-equation models that are nonadditive in unobservable random terms, single-equation models that possess and index structure, simultaneous equations nonadditive in unobservable random terms, and discrete choice models. Then, particular ways of achieving identification are considered. These include making use of conditional independence restrictions, marginal independence restrictions, shape restrictions on functions, shape restrictions on distributions, and restrictions in both functions and distributions. The objective is to provide insight into some of the recent techniques that have been developed recently, rather than on presenting a complete survey of the literature. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Matzkin, Rosa},
doi = {10.1016/S1573-4412(07)06073-4},
file = {:home/stefan/Dropbox/Academia/Library/Matzkin{\_}2007{\_}Nonparametric identification.pdf:pdf},
isbn = {9780444532008},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {identification,nonadditive models,nonparametric models,nonseparable models,simultaneous equations},
number = {SUPPL. PART B},
pages = {5307--5368},
title = {{Nonparametric identification}},
volume = {6},
year = {2007}
}
@article{Watson1994,
author = {Watson, Mark W.},
doi = {10.1086/669681},
file = {:home/stefan/Dropbox/Academia/Library/Watson{\_}1994{\_}Vector Autoregressions' and Cointegration.pdf:pdf},
issn = {0022-3808},
journal = {Handbook of Econometrics},
title = {{Vector Autoregressions' and Cointegration}},
year = {1994}
}
@article{Hamilton1994,
author = {Hamilton, James D},
file = {:home/stefan/Dropbox/Academia/Library/Hamilton{\_}1994{\_}State-space models.pdf:pdf},
journal = {Handbook of Econometrics},
number = {50},
title = {{State-space models}},
url = {papers3://publication/uuid/C703560F-8D7B-4A84-AD5F-DE0717F1FC3A},
volume = {4},
year = {1994}
}
@article{Bond2007,
abstract = {We survey recent microeconometric research on investment and employment that has used panel data on individual firms or plants. We focus on model specification and econometric estimation issues, but we also review some of the main empirical findings. We discuss advantages and limitations of microeconomic data in this context. We briefly review the neoclassical theory of the demand for capital and labour, on which most of the econometric models of investment and employment that we consider are based. We pay particular attention to dynamic factor demand models, based on the assumption that there are costs of adjustment, which have played a prominent role especially in the microeconometric literature on investment. With adjustment costs, current choices depend on expectations of future conditions. We discuss the challenges that this raises for econometric model specification, and some of the solutions that have been adopted. We also discuss estimation issues that arise for dynamic factor demand equations in the context of micro panel data for firms or plants. We then discuss a number of topics that have been the focus of recent microeconometric research on investment and employment. In particular, we review the literatures on investment and financing constraints, relative price effects on investment and employment, investment and uncertainty, investment in research and development (R{\&}D), elasticities of substitution and complementarity between technology, capital and skilled and unskilled labour, and recent work on models with non-convex adjustment costs. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Bond, Stephen and {Van Reenen}, John},
doi = {10.1016/S1573-4412(07)06065-5},
file = {:home/stefan/Dropbox/Academia/Library/Bond, Van Reenen{\_}2007{\_}Microeconometric Models of Investment and Employment.pdf:pdf},
isbn = {9780444506313},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {employment,investment,panel data},
number = {SUPPL. PART A},
pages = {4417--4498},
title = {{Microeconometric Models of Investment and Employment}},
volume = {6},
year = {2007}
}
@article{Andrews1994,
author = {Andrews, Donald W.K.},
file = {:home/stefan/Dropbox/Academia/Library/Andrews{\_}1994{\_}Empirical Process Methods in Econometrics.pdf:pdf},
journal = {Handbook of Econometrics},
title = {{Empirical Process Methods in Econometrics}},
volume = {IV},
year = {1994}
}
@article{Ichimura2007,
abstract = {This chapter reviews recent advances in nonparametric and semiparametric estimation, with an emphasis on applicability to empirical research and on resolving issues that arise in implementation. It considers techniques for estimating densities, conditional mean functions, derivatives of functions and conditional quantiles in a flexible way that imposes minimal functional form assumptions. The chapter begins by illustrating how flexible modeling methods have been applied in empirical research, drawing on recent examples of applications from labor economics, consumer demand estimation and treatment effects models. Then, key concepts in semiparametric and nonparametric modeling are introduced that do not have counterparts in parametric modeling, such as the so-called curse of dimensionality, the notion of models with an infinite number of parameters, the criteria used to define optimal convergence rates, and "dimension-free" estimators. After defining these new concepts, a large literature on nonparametric estimation is reviewed and a unifying framework presented for thinking about how different approaches relate to one another. Local polynomial estimators are discussed in detail and their distribution theory is developed. The chapter then shows how nonparametric estimators form the building blocks for many semiparametric estimators, such as estimators for average derivatives, index models, partially linear models, and additively separable models. Semiparametric methods offer a middle ground between fully nonparametric and parametric approaches. Their main advantage is that they typically achieve faster rates of convergence than fully nonparametric approaches. In many cases, they converge at the parametric rate. The second part of the chapter considers in detail two issues that are central with regard to implementing flexible modeling methods: how to select the values of smoothing parameters in an optimal way and how to implement "trimming" procedures. It also reviews newly developed techniques for deriving the distribution theory of semiparametric estimators. The chapter concludes with an overview of approximation methods that speed up the computation of nonparametric estimates and make flexible estimation feasible even in very large size samples. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Ichimura, Hidehiko and Todd, Petra E.},
doi = {10.1016/S1573-4412(07)06074-6},
file = {:home/stefan/Dropbox/Academia/Library/Ichimura, Todd{\_}2007{\_}Implementing Nonparametric and Semiparametric Estimators.pdf:pdf},
isbn = {9780444532008},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {additively separable models,asymptotic distribution theory,average derivative estimator,binning algorithms,convergence rates,flexible modeling,index models,least absolute deviations estimator,local polynomial estimators,maximum score estimator,nonparametric estimation,semiparametric estimation,semiparametric least squares estimator,smoothing parameter choice,trimming},
number = {SUPPL. PART B},
pages = {5369--5468},
title = {{Implementing Nonparametric and Semiparametric Estimators}},
volume = {6},
year = {2007}
}
@article{Klein1986,
author = {Klein, Lawrence R.},
doi = {10.1142/9789812830333_0033},
file = {:home/stefan/Dropbox/Academia/Library/Klein{\_}1986{\_}Economic Policy Formation Theory and Implementation (Applied Econometrics in the Public Sector).pdf:pdf},
journal = {Handbook of Econometrics},
title = {{Economic Policy Formation: Theory and Implementation (Applied Econometrics in the Public Sector)}},
year = {1986}
}
@article{Reiss2007,
abstract = {This chapter explains the logic of structural econometric models and compares them to other types of econometric models. We provide a framework researchers can use to develop and evaluate structural econometric models. This framework pays particular attention to describing different sources of unobservables in structural models. We use our framework to evaluate several literatures in industrial organization economics, including the literatures dealing with market power, product differentiation, auctions, regulation and entry. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Reiss, Peter C. and Wolak, Frank A.},
doi = {10.1016/S1573-4412(07)06064-3},
file = {:home/stefan/Dropbox/Academia/Library/Reiss, Wolak{\_}2007{\_}Structural Econometric Modeling Rationales and Examples from Industrial Organization.pdf:pdf},
isbn = {9780444506313},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {auctions,entry,market power,regulation,structural econometric model},
number = {SUPPL. PART A},
pages = {4277--4415},
title = {{Structural Econometric Modeling: Rationales and Examples from Industrial Organization}},
volume = {6},
year = {2007}
}
@article{Gourieroux1994,
author = {Gourieroux, C and Monfort, A},
file = {:home/stefan/Dropbox/Academia/Library/Gourieroux, Monfort{\_}1994{\_}Testing non-nested hypotheses.pdf:pdf},
journal = {Handbook of Econometrics},
number = {44},
title = {{Testing non-nested hypotheses}},
url = {papers3://publication/uuid/4D7C6FBD-0AB5-4792-A3DC-DB70A5FA26DE},
volume = {4},
year = {1994}
}
@article{Chen2007,
abstract = {Often researchers find parametric models restrictive and sensitive to deviations from the parametric specifications; semi-nonparametric models are more flexible and robust, but lead to other complications such as introducing infinite-dimensional parameter spaces that may not be compact and the optimization problem may no longer be well-posed. The method of sieves provides one way to tackle such difficulties by optimizing an empirical criterion over a sequence of approximating parameter spaces (i.e., sieves); the sieves are less complex but are dense in the original space and the resulting optimization problem becomes well-posed. With different choices of criteria and sieves, the method of sieves is very flexible in estimating complicated semi-nonparametric models with (or without) endogeneity and latent heterogeneity. It can easily incorporate prior information and constraints, often derived from economic theory, such as monotonicity, convexity, additivity, multiplicity, exclusion and nonnegativity. It can simultaneously estimate the parametric and nonparametric parts in semi-nonparametric models, typically with optimal convergence rates for both parts. This chapter describes estimation of semi-nonparametric econometric models via the method of sieves. We present some general results on the large sample properties of the sieve estimates, including consistency of the sieve extremum estimates, convergence rates of the sieve M-estimates, pointwise normality of series estimates of regression functions, root-n asymptotic normality and efficiency of sieve estimates of smooth functionals of infinite-dimensional parameters. Examples are used to illustrate the general results. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Chen, Xiaohong},
doi = {10.1016/S1573-4412(07)06076-X},
file = {:home/stefan/Dropbox/Academia/Library/Chen{\_}2007{\_}Large Sample Sieve Estimation of Semi-Nonparametric Models.pdf:pdf},
isbn = {9780444532008},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {endogeneity in semi-nonparametric models,semiparametric two-step estimation,series,sieve extremum estimation,sieve minimum distance},
number = {SUPPL. PART B},
pages = {5549--5632},
title = {{Large Sample Sieve Estimation of Semi-Nonparametric Models}},
volume = {6},
year = {2007}
}
@book{Chesher2020,
abstract = {This chapter sets out the extension of the scope of the classical IV model to cases in which unobserved variables are set-valued functions of observed variables. The resulting Generalized IV (GIV) models can be used when outcomes are discrete while unobserved variables are continuous, when there are rich specifications of heterogeneity as in random coefficient models, and when there are inequality restrictions constraining observed outcomes and unobserved variables. There are many other applications and classical IV models arise as a special case. The chapter provides characterizations of the identified sets delivered by GIV models. It gives details of the application of GIV analysis to models with an interval censored endogenous variable and to binary outcome models – for example probit models – with endogenous explanatory variables. It illustrates how the identified sets delivered by GIV models can be represented by moment inequality characterizations that have been the focus of recently developed methods for inference. An empirical application to a binary outcome model of female labor force participation is worked through in detail.},
author = {Chesher, Andrew and Rosen, Adam M.},
booktitle = {Handbook of Econometrics},
doi = {10.1016/bs.hoe.2019.11.001},
file = {:home/stefan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chesher, Rosen - 2020 - Generalized instrumental variable models, methods, and applications.pdf:pdf},
isbn = {9780444636492},
issn = {15734412},
keywords = {Instrumental variables,discrete outcomes,endogeneity,excess heterogeneity,incomplete models,interval censoring,moment inequalities,partial identification,random sets,structural econometrics},
pages = {1--110},
publisher = {Elsevier B.V.},
title = {{Generalized instrumental variable models, methods, and applications}},
url = {https://doi.org/10.1016/bs.hoe.2019.11.001},
volume = {7},
year = {2020}
}
@article{Intriligator1983,
author = {Intriligator, Michael D},
file = {:home/stefan/Dropbox/Academia/Library/Intriligator{\_}1983{\_}Economic and econometric models.pdf:pdf},
journal = {Handbook of Econometrics},
number = {3},
title = {{Economic and econometric models}},
url = {papers3://publication/uuid/5C442031-8A7E-4CAA-9BE1-A47F37B8A5F5},
volume = {1},
year = {1983}
}
@article{Hausman1983a,
author = {Hausman, Jerry a},
doi = {10.1016/S1573-4412(83)01011-9},
file = {:home/stefan/Dropbox/Academia/Library/Hausman{\_}1983{\_}Specification and estimation of simultaneous equation models.pdf:pdf},
isbn = {9780444861856},
issn = {15734412},
journal = {Handbook of Econometrics},
number = {7},
pages = {391--448},
title = {{Specification and estimation of simultaneous equation models}},
url = {http://www.sciencedirect.com/science/article/pii/S1573441283010119{\%}5Cnpapers3://publication/uuid/0482BCC8-5981-4F4F-91D1-CA7584834538},
volume = {1},
year = {1983}
}
@article{Krasker1983,
author = {Krasker, William S and Kuh, Edwin and Welsch, Roy E},
file = {:home/stefan/Dropbox/Academia/Library/Krasker, Kuh, Welsch{\_}1983{\_}Estimation for dirty data and flawed models.pdf:pdf},
journal = {Handbook of Econometrics},
number = {11},
title = {{Estimation for dirty data and flawed models}},
url = {papers3://publication/uuid/E4A36CEE-9A8A-427F-97C6-966E6EC32F77},
volume = {1},
year = {1983}
}
@book{Gagliardini2020,
abstract = {This chapter surveys recent econometric methodologies for inference in large dimensional conditional factor models in finance. Changes in the business cycle and asset characteristics induce time variation in factor loadings and risk premia to be accounted for. The growing trend in the use of disaggregated data for individual securities motivates our focus on methodologies for a large number of assets. The chapter starts with a historical perspective on conditional factor models with a small number of assets for comparison purpose. Then, it outlines the concept of approximate factor structure in the presence of conditional information, and reviews an arbitrage pricing theory for large dimensional factor models in this framework. For inference, we distinguish between two different cases depending on whether factors are observable or not. We focus on diagnosing model specification, estimating conditional risk premia, and testing asset pricing restrictions under increasing cross-sectional and time series dimensions. At the end of the chapter, we provide new empirical findings based on a broad set of factor models and contrast analysis based on individual stocks and standard sets of portfolios. We also discuss the impact on computing time-varying cost of equity for a firm, and summarize differences between results for developed and emerging markets in an international setting.},
author = {Gagliardini, Patrick and Ossola, Elisa and Scaillet, Olivier},
booktitle = {Handbook of Econometrics},
doi = {10.1016/bs.hoe.2020.10.001},
file = {:home/stefan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gagliardini, Ossola, Scaillet - 2020 - Estimation of large dimensional conditional factor models in finance.pdf:pdf},
issn = {15734412},
keywords = {Asset pricing,Conditional information,Emerging markets,Factor model,Large panel,Risk premium},
pages = {219--282},
publisher = {Elsevier B.V.},
title = {{Estimation of large dimensional conditional factor models in finance}},
url = {https://doi.org/10.1016/bs.hoe.2020.10.001},
volume = {7},
year = {2020}
}
@article{Chib2001,
author = {Chib, Siddhartha},
file = {:home/stefan/Dropbox/Academia/Library/Chib{\_}2001{\_}Marcov Chain Monte Carlo Methods Computation and Inference.pdf:pdf},
journal = {Handbook of Econometrics},
pages = {3569--3649},
title = {{Marcov Chain Monte Carlo Methods: Computation and Inference}},
volume = {5},
year = {2001}
}
@article{Geweke1984,
author = {Geweke, John},
file = {:home/stefan/Dropbox/Academia/Library/Geweke{\_}1984{\_}Inference and Causality in Economic Time Series.pdf:pdf},
journal = {Handbook of Econometrics,},
pages = {1102--1144},
title = {{Inference and Causality in Economic Time Series}},
volume = {II},
year = {1984}
}
@book{Amemiya1983,
author = {Amemiya, Takeshi},
booktitle = {Handbook of Econometrics},
doi = {10.1016/0026-2714(83)90385-2},
file = {:home/stefan/Dropbox/Academia/Library/Amemiya{\_}1983{\_}Non-Linear Regression Models.pdf:pdf},
issn = {00262714},
title = {{Non-Linear Regression Models}},
year = {1983}
}
@article{Quandt1983,
author = {Quandt, Richard E},
file = {:home/stefan/Dropbox/Academia/Library/Quandt{\_}1983{\_}Computational problems and methods BT.pdf:pdf},
journal = {Handbook of Econometrics},
number = {12},
title = {{Computational problems and methods BT}},
url = {papers3://publication/uuid/1398833A-9CD6-4BD7-A198-CD26CE45ADFD},
volume = {1},
year = {1983}
}
@article{Bound2001,
author = {Bound, John and Brown, Charles and Mathiowetz, Nancy},
file = {:home/stefan/Dropbox/Academia/Library/Bound, Brown, Mathiowetz{\_}2001{\_}Measurement Error in Survey Data.pdf:pdf},
journal = {Handbook of Econometrics},
keywords = {attenuation},
number = {59},
pages = {3705--3843},
title = {{Measurement Error in Survey Data}},
url = {http://www.sciencedirect.com/science/article/B7GX7-4DXJCWR-1M/2/90c6de4bee614acfb9b03e96ed021274{\%}0A(null)},
volume = {5},
year = {2001}
}
@article{Newey1994,
author = {Newey, Whitney K and McFadden, Daniel},
file = {:home/stefan/Dropbox/Academia/Library/Newey, McFadden{\_}1994{\_}Large Sample Estimation and Hypothesis Testing.pdf:pdf},
journal = {Handbook of Econometrics},
number = {36},
pages = {2112--2245},
title = {{Large Sample Estimation and Hypothesis Testing}},
volume = {4},
year = {1994}
}
@article{Hajivassiliou1994,
abstract = {We introduce a one dimensional contact process for which births to the right of the rightmost particle and to the left of the leftmost particle occur at rate $\lambda$e (where e is for external). Other births occur at rate $\lambda$i (where i is for internal). Deaths occur at rate 1. The case $\lambda$e = $\lambda$i is the well known basic contact process for which there is a critical value $\lambda$c {\textgreater} 1 such that if the birth rate is larger than $\lambda$c the process has a positive probability of surviving. Our main motivation here is to understand the relative importance of the external birth rates. We show that if $\lambda$e ≤ 1 then the process always dies out while if $\lambda$e {\textgreater} 1 and if $\lambda$i is large enough then the process may survive. We also show that if $\lambda$i {\textless} $\lambda$c the process dies out for all $\lambda$e. To extend this notion to d {\textgreater} 1 we introduce a second process that has an epidemiological interpretation. For this process each site can be in one of three states: infected, a susceptible that has never been infected, or a susceptible that has been infected previously. Furthermore, the rates at which the two types of susceptible become infected are different. We obtain some information about the phase diagram about this case as well.},
author = {Hajivassiliou, V.A. and Ruud, P.A.},
file = {:home/stefan/Dropbox/Academia/Library/Hajivassiliou, Ruud{\_}1994{\_}Classical estimation methods models using simulation.pdf:pdf},
journal = {Handbook of Econometrics},
title = {{Classical estimation methods models using simulation}},
volume = {I},
year = {1994}
}
@book{Wooldridge1994,
author = {Wooldridge, Jeffrey M},
booktitle = {Handbook of Econometrics},
file = {:home/stefan/Dropbox/Academia/Library/Wooldridge{\_}1994{\_}Estimation and Inference for Dependent Processes.pdf:pdf},
title = {{Estimation and Inference for Dependent Processes}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1573441205800145},
volume = {5},
year = {1994}
}
@article{Jorgenson1986,
author = {Jorgenson, Dale W.},
file = {:home/stefan/Dropbox/Academia/Library/Jorgenson{\_}1986{\_}Econometric methods for modeling producer behavior.pdf:pdf},
journal = {Handbook of Econometrics},
pages = {1841--1915},
title = {{Econometric methods for modeling producer behavior}},
year = {1986}
}
@article{Maddala1986,
author = {Maddala, G. S.},
file = {:home/stefan/Dropbox/Academia/Library/Maddala{\_}1986{\_}Disequilibrium, Self-Selection and Switching Models.pdf:pdf},
journal = {Handbook of Econometrics},
title = {{Disequilibrium, Self-Selection and Switching Models}},
volume = {III},
year = {1986}
}
@article{Geweke2001,
author = {Geweke, John and Keane, Michael},
file = {:home/stefan/Dropbox/Academia/Library/Geweke, Keane{\_}2001{\_}Computationally intensive methods for integration in econometrics.pdf:pdf},
journal = {Handbook of Econometrics},
number = {56},
title = {{Computationally intensive methods for integration in econometrics}},
url = {papers3://publication/uuid/057F62E1-5EDE-4FEF-B344-2CD0D3497C32},
volume = {5},
year = {2001}
}
@article{Heckman2007a,
abstract = {This chapter uses the marginal treatment effect (MTE) to unify and organize the econometric literature on the evaluation of social programs. The marginal treatment effect is a choice-theoretic parameter that can be interpreted as a willingness to pay parameter for persons at a margin of indifference between participating in an activity or not. All of the conventional treatment parameters as well as the more economically motivated treatment effects can be generated from a baseline marginal treatment effect. All of the estimation methods used in the applied evaluation literature, such as matching, instrumental variables, regression discontinuity methods, selection and control function methods, make assumptions about the marginal treatment effect which we exposit. Models for multiple outcomes are developed. Empirical examples of the leading methods are presented. Methods are presented for bounding treatment effects in partially identified models, when the marginal treatment effect is known only over a limited support. We show how to use the marginal treatment in econometric cost benefit analysis, in defining limits of policy experiments, in constructing the average marginal treatment effect, and in forecasting the effects of programs in new environments. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Heckman, James J. and Vytlacil, Edward J.},
doi = {10.1016/S1573-4412(07)06071-0},
file = {:home/stefan/Dropbox/Academia/Library/Heckman, Vytlacil{\_}2007{\_}Econometric Evaluation of Social Programs, Part II Using the Marginal Treatment Effect to Organize Alternative Ec.pdf:pdf},
isbn = {9780444532008},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {bounds,econometric cost benefit analysis,forecasting new policies,instrumental variables,marginal treatment effect,matching,policy evaluation,regression discontinuity},
number = {SUPPL. PART B},
pages = {4875--5143},
title = {{Econometric Evaluation of Social Programs, Part II: Using the Marginal Treatment Effect to Organize Alternative Econometric Estimators to Evaluate Social Programs, and to Forecast their Effects in New Environments}},
volume = {6},
year = {2007}
}
@book{Schennach2020,
abstract = {This chapter overviews the recent progress towards the identification and the estimation of models in which some of the variables are either imperfectly measured or even entirely unobserved, with a special focus on models with nonlinear, nonparametric, nonclassical or nonseparable features. Starting from the basic treatment of nonlinear models with measurement error assuming a known measurement error distribution or validation data availability, we then turn to the methods relying on more readily available auxiliary variables (such as repeated measurements, instrumental variables or general indicators). These models are then extended to fully nonlinear nonparametric and nonseparable factor models and to general latent (i.e. unobserved) variables models, in which the features of the latent variables are indirectly inferred from their effects on observables. We also identify important connections with related fields, such as nonlinear panel data, limited dependent variables, game theoretic models, dynamic models and set-identification.},
author = {Schennach, Susanne M.},
booktitle = {Handbook of Econometrics},
doi = {10.1016/bs.hoe.2020.07.001},
file = {:home/stefan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schennach - 2020 - Mismeasured and unobserved variables.pdf:pdf},
issn = {15734412},
keywords = {Latent variables,errors-in-variables,factor models,misclassification,nonclassical errors,set-identification},
pages = {487--565},
publisher = {Elsevier B.V.},
title = {{Mismeasured and unobserved variables}},
url = {https://doi.org/10.1016/bs.hoe.2020.07.001},
volume = {7},
year = {2020}
}
@article{Athey2007,
abstract = {This chapter discusses structural econometric approaches to auctions. Remarkably, much of what can be learned from auction data can be learned without restrictions beyond those derived from the relevant economic model. This enables us to take a nonparametric perspective in discussing how the structure of auction models can be combined with observables to uncover (or test hypotheses about) primitives of interest in auction markets. We focus on first-price sealed-bid and ascending auctions, including extensions to Dutch auctions, Internet auctions, multi-unit auctions, and multi-object auctions. We consider a wide range of underlying structures of bidder demand and information, as well as a variety of types of data one may encounter in applications. We discuss identification and testable restrictions of these models and present a variety of estimation approaches. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Athey, Susan and Haile, Philip A.},
doi = {10.1016/S1573-4412(07)06060-6},
file = {:home/stefan/Dropbox/Academia/Library/Athey, Haile{\_}2007{\_}Nonparametric Approaches to Auctions.pdf:pdf},
isbn = {9780444506313},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {auctions,estimation,identification,testing},
number = {SUPPL. PART A},
pages = {3847--3965},
title = {{Nonparametric Approaches to Auctions}},
volume = {6},
year = {2007}
}
@article{Hansen2007,
abstract = {We study structural models of stochastic discount factors and explore alternative methods of estimating such models using data on macroeconomic risk and asset returns. Particular attention is devoted to recursive utility models in which risk aversion can be modified without altering intertemporal substitution. We characterize the impact of changing the intertemporal substitution and risk aversion parameters on equilibrium short-run and long-run risk prices and on equilibrium wealth. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Hansen, Lars Peter and Heaton, John and Lee, Junghoon and Roussanov, Nikolai},
doi = {10.1016/S1573-4412(07)06061-8},
file = {:home/stefan/Dropbox/Academia/Library/Hansen et al.{\_}2007{\_}Intertemporal Substitution and Risk Aversion.pdf:pdf},
isbn = {9780444506313},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {GMM,asset pricing,intertemporal substitution,recursive utility,risk aversion},
number = {SUPPL. PART A},
pages = {3967--4056},
title = {{Intertemporal Substitution and Risk Aversion}},
volume = {6},
year = {2007}
}
@article{MaCurdy2007,
abstract = {This chapter presents a unified set of estimation methods for fitting a rich array of models describing dynamic relationships within a longitudinal data setting. The discussion surveys approaches for characterizing the micro dynamics of continuous dependent variables both over time and across individuals, focusing on two flexible sets of empirical specifications: dynamic simultaneous equations models incorporating error-components structures, and autoregressive quantile models. The chapter is motivated by the principle that, whenever possible, estimation methods should rely on routines available in familiar software packages to make them accessible to a wide range of practitioners. Conventional method-of-moments procedures offer a general apparatus for estimating parameters of panel-data specifications, though one must introduce a series of modifications to overcome challenges arising from: (1) use of unbalanced data structures, (2) weighting to account for stratified sampling inherent in survey longitudinal data, (3) incorporation of predetermined variables in estimation, and (4) computational complexities confronted when estimating large systems of equations with intricate intertemporal restrictions. To allow researchers to separate the estimation of longitudinal time-series specifications into manageable pieces, the discussion describes multi-step approaches that estimate subsets of parameters appearing in a single model component (such as the autoregressive or moving-average structure of the error process) without having to estimate all parameters of the entire model jointly. Such procedures offer a powerful set of diagnostic tools for narrowing model choices and for selecting among specifications that fit the underlying data. To illustrate all of the econometric methods outlined in this chapter, the analysis presents a set of empirical applications summarizing the dynamic properties of hourly wages for adult men using data from the Panel Study of Income Dynamics. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {MaCurdy, Thomas},
doi = {10.1016/S1573-4412(07)06062-X},
file = {:home/stefan/Dropbox/Academia/Library/MaCurdy{\_}2007{\_}A Practitioner's Approach to Estimating Intertemporal Relationships Using Longitudinal Data Lessons from Applications in Wa.pdf:pdf},
isbn = {9780444506313},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {ARMA,autoregressive,dynamic quantile regressions,dynamic simultaneous equations,earnings dynamics,error structure,longitudinal data,method of moments,multi-step estimation,nonlinear simultaneous equations,optimal instruments,sample weighting,stratified sample,times series,unbalanced data},
number = {SUPPL. PART A},
pages = {4057--4167},
title = {{A Practitioner's Approach to Estimating Intertemporal Relationships Using Longitudinal Data: Lessons from Applications in Wage Dynamics}},
volume = {6},
year = {2007}
}
@book{Graham2020,
abstract = {Many economic activities are embedded in networks: sets of agents and the (often) rivalrous relationships connecting them to one another. Input sourcing by firms, interbank lending, scientific research, and job search are four examples, among many, of networked economic activities. Motivated by the premise that networks' structures are consequential, this chapter describes econometric methods for analyzing them. I emphasize (i) dyadic regression analysis incorporating unobserved agent-specific heterogeneity and supporting causal inference, (ii) techniques for estimating, and conducting inference on, summary network parameters (e.g., the degree distribution or transitivity index); and (iii) empirical models of strategic network formation admitting interdependencies in preferences. Current research challenges and open questions are also discussed.},
archivePrefix = {arXiv},
arxivId = {1912.06346},
author = {Graham, Bryan S.},
booktitle = {Handbook of Econometrics},
doi = {10.1016/bs.hoe.2020.05.001},
eprint = {1912.06346},
file = {:home/stefan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Graham - 2020 - Network data.pdf:pdf},
issn = {15734412},
keywords = {Network data,U-Statistics,dyadic regression,gravity models,network moments,network statistics,strategic network formation},
pages = {111--218},
publisher = {Elsevier B.V.},
title = {{Network data}},
url = {https://doi.org/10.1016/bs.hoe.2020.05.001},
volume = {7},
year = {2020}
}
@article{Bergstrom1984,
author = {Bergstrom, A R},
file = {:home/stefan/Dropbox/Academia/Library/Bergstrom{\_}1984{\_}Continous Time Stochastic Models and Issues of Aggregation over Time.pdf:pdf},
journal = {Handbook of Econometrics},
title = {{Continous Time Stochastic Models and Issues of Aggregation over Time}},
volume = {II},
year = {1984}
}
@article{MacKenzie2013,
abstract = {The present study investigated psychophysiological responses to emotional feedback in a computerised problem-solving experiment. 40 subjects solved 27 series of mathematical tasks. After each series, a speech synthesiser gave emotionally negative, neutral, or positive feedback. Response times and error-rates to calculations following the different feedback categories were analysed. Pupil size was measured during and five seconds after each feedback category. Ratings of the feedback categories were also measured. The ratings showed that the different feedback categories were effective in eliciting congruent emotions in the subjects. The task times were significantly shorter after positive than negative feedback. Error rates were not affected by the feedback. The pupil size was significantly smaller after the feedback than during it. After positive feedback, there was a significantly faster decrease in the pupil diameter than after the other feedback categories. Thus, positive emotional feedback had beneficial effects on human behaviour and physiology in human-computer interaction.},
author = {MacKenzie, I. Scott},
doi = {10.1016/B978-0-12-405865-1.00006-6},
file = {:home/stefan/Dropbox/Academia/Library/MacKenzie{\_}2013{\_}Hypothesis Testing.pdf:pdf},
isbn = {9780124058651},
issn = {1554-3528},
journal = {Handbook of Econometrics},
pages = {191--232},
title = {{Hypothesis Testing}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9780124058651000066},
volume = {II},
year = {2013}
}
@book{Dawkins2001,
author = {Dawkins, Christina and Srinivasan, TN and Whalley, John},
booktitle = {Handbook of Econometrics},
file = {:home/stefan/Dropbox/Academia/Library/Dawkins, Srinivasan, Whalley{\_}2001{\_}Calibration.pdf:pdf},
title = {{Calibration}},
volume = {5},
year = {2001}
}
@article{Ridder2007,
abstract = {Economists who use survey or administrative data for inferences regarding a population may want to combine information obtained from two or more samples drawn from the population. This is the case if there is no single sample that contains all relevant variables. A special case occurs if longitudinal or panel data are needed but only repeated cross-sections are available. In this chapter we survey sample combination. If two (or more) samples from the same population are combined, there are variables that are unique to one of the samples and variables that are observed in each sample. What can be learned by combining such samples, depends on the nature of the samples, the assumptions that one is prepared to make, and the goal of the analysis. The most ambitious objective is the identification and estimation of the joint distribution, but often we settle for the estimation of economic models that involve these variables or a subset thereof. Sometimes the goal is to reduce biases due to mismeasured variables. We consider sample merger by matching on identifiers that may be imperfect in the case that the two samples have a substantial number of common units. For the case that the two samples are independent, we consider (conditional) bounds on the joint distribution. Exclusion restrictions will narrow these bounds. We also consider inference under the strong assumption of conditional independence. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Ridder, Geert and Moffitt, Robert},
doi = {10.1016/S1573-4412(07)06075-8},
file = {:home/stefan/Dropbox/Academia/Library/Ridder, Moffitt{\_}2007{\_}The Econometrics of Data Combination.pdf:pdf},
isbn = {9780444532008},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {matching,nonparametric identification,repeated cross-sections,sample combination},
number = {SUPPL. PART B},
pages = {5469--5547},
title = {{The Econometrics of Data Combination}},
volume = {6},
year = {2007}
}
@article{Blundell2007b,
author = {Blundell, Richard and Stoker, Thomas},
doi = {10.1016/S1573-4412(07)06068-0},
file = {:home/stefan/Dropbox/Academia/Library/Blundell, Stoker{\_}2007{\_}Models of aggregate economic relationships that account for heterogeneity.pdf:pdf},
journal = {Handbook of Econometrics},
pages = {4610--4666},
title = {{Models of aggregate economic relationships that account for heterogeneity}},
url = {http://www.sciencedirect.com/science/article/pii/S1573441207060680},
volume = {Volume 6a},
year = {2007}
}
@article{McFadden1974,
abstract = {The subject of this chapter is the econometric analysis of qualitative endogenous variables. Such variables may result from economic behavior which is intrinsically categorical, such as choice of occupation, marriage partner, or entry into a product market. Alternatively, they may come from classification during observation, such as the coding of housing choices into 'sub-standard' or 'standard'. Qualitative variables may be binomial (yes/no) or multinomial, and multinomial responses may be naturally ordered(number of telephone calls) or unordered (freight shipment mode). There may also be multivariate combinations of discrete and continuous variables (appliance portfolio and energy consumption). Binomial and multinomial models are the primary subject of this chapter. A final section considers extensions.},
author = {McFadden, Daniel},
file = {:home/stefan/Dropbox/Academia/Library/McFadden{\_}1974{\_}Econometric analysis of qualitative reponse models.pdf:pdf},
journal = {Handbook of Econometrics, vol. II},
keywords = {Econometric analysis},
pages = {1396--1446},
title = {{Econometric analysis of qualitative reponse models}},
url = {http://www.ses.wsu.edu/people/faculty/LaFrance/Courses/EconS514/Handbook-of-Econometrics/Volume-2/McFadden-hoe-1984.pdf},
volume = {II},
year = {1974}
}
@article{Brock2001,
author = {Brock, William A and Durlauf, Steven N},
file = {:home/stefan/Dropbox/Academia/Library/Brock, Durlauf{\_}2001{\_}Interactions-based models.pdf:pdf},
journal = {Handbook of Econometrics},
number = {54},
title = {{Interactions-based models}},
url = {papers3://publication/uuid/CC8E467D-A43E-4AB1-BAC9-074304A45578},
volume = {5},
year = {2001}
}
@article{Powell1994,
abstract = {A semiparametric model for observational data combines a parametric form for some component of the data generating process (usually the behavioral relation between the dependent and explanatory variables) with weak nonparametric restrictions on the remainder of the model (usually the distribution of the unobservable errors). This chapter surveys some of the recent literature on semiparametric methods, emphasizing microeconometric applications using limited dependent variable models. An introductory section defines semiparametric models more precisely and reviews the techniques used to derive the large-sample properties of the corresponding estimation methods. The next section describes a number of weak restrictions on error distributions - conditional mean, conditional quantile, conditional symmetry, independence, and index restrictions - and show how they can be used to derive identifying restrictions on the distributions of observables. This general discussion is followed by a survey of a number of specific estimators proposed for particular econometric models, and the chapter concludes with a brief account of applications of these methods in practice. {\textcopyright} 1994 Elsevier Science B.V. All rights reserved.},
author = {Powell, James L.},
doi = {10.1016/S1573-4412(05)80010-8},
file = {:home/stefan/Dropbox/Academia/Library/Powell{\_}1994{\_}Estimation of semiparametric models.pdf:pdf},
isbn = {9780444887665},
issn = {15734412},
journal = {Handbook of Econometrics},
pages = {2443--2521},
title = {{Estimation of semiparametric models}},
volume = {4},
year = {1994}
}
@article{Horowitz2001,
author = {Horowitz, Joel L.},
doi = {10.1016/S0304-4076(00)00051-8},
file = {:home/stefan/Dropbox/Academia/Library/Horowitz{\_}2001{\_}The Bootstrap.pdf:pdf},
issn = {03044076},
journal = {Handbook of Econometrics},
title = {{The Bootstrap}},
year = {2001}
}
@article{Hardle1994,
abstract = {We review different approaches to nonparametric density and regression estimation. Kernel estimators are motivated from local averaging and solving ill-posed problems. Kernel estimators are compared to k-NN estimators, orthogonal series and splines. Pointwise and uniform confidence bands are described, and the choice of smoothing parameter is discussed. Finally, the method is applied to nonparametric prediction of time series and to semiparametric estimation. ?? 1994 Elsevier Science B.V. All rights reserved.},
author = {H{\"{a}}rdle, Wolfgang Karl and Linton, O.},
file = {:home/stefan/Dropbox/Academia/Library/H{\"{a}}rdle, Linton{\_}1994{\_}Applied Nonparametric Methods.pdf:pdf},
journal = {Handbook of Econometrics},
keywords = {nonparametric estimation},
number = {26},
pages = {2295--2339},
title = {{Applied Nonparametric Methods}},
url = {http://www.sciencedirect.com/science/article/pii/S1573441205800078},
volume = {IV},
year = {1994}
}
@article{Fair1986,
author = {Fair, Ray C},
file = {:home/stefan/Dropbox/Academia/Library/Fair{\_}1986{\_}Evaluating the predictive accuracy of models.pdf:pdf},
journal = {Handbook of Econometrics},
number = {33},
title = {{Evaluating the predictive accuracy of models}},
url = {papers3://publication/uuid/D1A33263-D302-4A63-8F62-0593D4B49F19},
volume = {3},
year = {1986}
}
@article{Rust1994,
author = {Rust, John},
file = {:home/stefan/Dropbox/Academia/Library/Rust{\_}1994{\_}Structual estimation of Markov decision processes.pdf:pdf},
journal = {Handbook of Econometrics},
number = {51},
title = {{Structual estimation of Markov decision processes}},
url = {papers3://publication/uuid/26BF22B4-E5F6-4F45-9F1D-850FCF98F26E},
volume = {4},
year = {1994}
}
@article{Arellano2001,
abstract = {This chapter focuses on two of the developments in panel data econometrics since the Handbook chapter by Chamberlain (1984). The first objective of this chapter is to provide a review of linear panel data models with predetermined variables. We discuss the implications of assuming that explanatory variables are predetermined as opposed to strictly exogenous in dynamic structural equations with unobserved heterogeneity. We compare the identification from moment conditions in each case, and the implications of alternative feedback schemes for the time series properties of the errors. We next consider autoregressive error component models under various auxiliary assumptions. There is a trade-off between robustness and efficiency since assumptions of stationary initial conditions or time series homoskedasticity can be very informative, but estimators are not robust to their violation. We also discuss the identification problems that arise in models with predetermined variables and multiple effects. Concerning inference in linear models with predetermined variables, we discuss the form of optimal instruments, and the sampling properties of GMM and LIML-analogue estimators drawing on Monte Carlo results and asymptotic approximations. A number of identification results for limited dependent variable models with fixed effects and strictly exogenous variables are available in the literature, as well as some results on consistent and asymptotically normal estimation of such models. There are also some results available for models of this type including lags of the dependent variable, although even less is known for nonlinear dynamic models. Reviewing the recent work on discrete choice and selectivity models with fixed effects is the second objective of this chapter. A feature of parametric limited dependent variable models is their fragility to auxiliary distributional assumptions. This situation prompted the development of a large literature dealing with semiparametric alternatives (reviewed in Powell, 1994's chapter). The work that we review in the second part of the chapter is thus at the intersection of the panel data literature and that on cross-sectional semiparametric limited dependent variable models.},
author = {Arellano, Manuel and Honor{\'{e}}, Bo},
doi = {10.1016/S1573-4412(01)05006-1},
file = {:home/stefan/Dropbox/Academia/Library/Arellano, Honor{\'{e}}{\_}2001{\_}Panel Data Models Some Recent Developments.pdf:pdf},
isbn = {9780444823403},
issn = {15734412},
journal = {Handbook of Econometrics},
pages = {3229--3296},
title = {{Panel Data Models: Some Recent Developments}},
url = {http://www.sciencedirect.com/science/article/pii/S1573441201050061},
volume = {5},
year = {2001}
}
@article{HeckmanSinger1986,
author = {Heckman, James and Singer, Burton},
file = {:home/stefan/Dropbox/Academia/Library/Heckman, Singer{\_}1986{\_}Econometric Analysis of Longitudinal Data.pdf:pdf},
journal = {Handbook of Econometrics},
title = {{Econometric Analysis of Longitudinal Data}},
volume = {III},
year = {1986}
}
@article{Heckman1986a,
abstract = {Summary This paper presents and extends the index function model of Karl Pearson (1901) that underlies all recent models in labor econometrics. In this framework, censored, truncated and discrete random variables are interpreted as the manifestation of various sampling schemes for underlying index function models. A unified derivation of the densities and regression representations for index function models is presented. Methods of estimation are discussed with an emphasis on regression and instrumental variable procedures. We demonstrate how a variety of substantive models in labor economics can be given an econometric representation within the index function framework. Models for the analysis of unemployment, labor force participation, job turnover, the impact of interventions on earnings (and other outcomes) and hours of work are formulated as special cases of the general index function model. By casting these diverse models in a common mold we demonstrate the essential commonalities in the econometric approach required for their formulation and estimation.},
author = {Heckman, James J and Macurdy, Thomas E and Griliches, Zvi and Intriligator, M D},
doi = {http://dx.doi.org/10.1016/S1573-4412(86)03012-X},
file = {:home/stefan/Dropbox/Academia/Library/Heckman et al.{\_}1986{\_}Labor econometrics.pdf:pdf},
isbn = {1573-4412},
journal = {Handbook of Econometrics},
pages = {1917--1977},
title = {{Labor econometrics}},
url = {http://www.sciencedirect.com/science/article/pii/S157344128603012X},
volume = {3},
year = {1986}
}
@book{Leamer1983,
author = {Leamer, E},
booktitle = {Handbook of Econometrics},
file = {:home/stefan/Dropbox/Academia/Library/Leamer{\_}1983{\_}Model Choice and Specification Analysis.pdf:pdf},
title = {{Model Choice and Specification Analysis}},
year = {1983}
}
@article{Chamberlain1984,
author = {Chamberlain, Gary},
doi = {10.1016/S1573-4412(84)02014-6},
file = {:home/stefan/Dropbox/Academia/Library/Chamberlain{\_}1984{\_}Panel data.pdf:pdf},
issn = {15734412},
journal = {Handbook of Econometrics},
pages = {1247--1318},
title = {{Panel data}},
volume = {2},
year = {1984}
}
@article{Aigner1984,
author = {Aigner, Dennis J and Hsiao, Cheng and Kapteyn, Arie and Wansbeek, Tom},
file = {:home/stefan/Dropbox/Academia/Library/Aigner et al.{\_}1984{\_}Latent variable models in econometrics.pdf:pdf},
journal = {Handbook of Econometrics},
number = {23},
title = {{Latent variable models in econometrics}},
url = {papers3://publication/uuid/728C27D7-C45A-4320-9CE9-C3C74CCAF273},
volume = {2},
year = {1984}
}
@article{Griliches1986,
author = {Griliches, Zvi},
file = {:home/stefan/Dropbox/Academia/Library/Griliches{\_}1986{\_}Economic data issues.pdf:pdf},
journal = {Handbook of Econometrics},
number = {25},
title = {{Economic data issues}},
url = {papers3://publication/uuid/EC033D67-1F80-4973-B669-778C93F7F9AC},
volume = {3},
year = {1986}
}
@article{Heckman2007,
abstract = {This chapter relates the literature on the econometric evaluation of social programs to the literature in statistics on "causal inference". In it, we develop a general evaluation framework that addresses well-posed economic questions and analyzes agent choice rules and subjective evaluations of outcomes as well as the standard objective evaluations of outcomes. The framework recognizes uncertainty faced by agents and ex ante and ex post evaluations of programs. It also considers distributions of treatment effects. These features are absent from the statistical literature on causal inference. A prototypical model of agent choice and outcomes is used to illustrate the main ideas. We formally develop models for counterfactuals and causality that build on Cowles Commission econometrics. These models anticipate and extend the literature on causal inference in statistics. The distinction between fixing and conditioning that has recently entered the statistical literature was first developed by Cowles economists. Models of simultaneous causality were also developed by the Cowles group, as were notions of invariance to policy interventions. These basic notions are updated to nonlinear and nonparametric frameworks for policy evaluation more general than anything in the current statistical literature on "causal inference". A formal discussion of identification is presented and applied to clearly formulated choice models used to evaluate social programs. {\textcopyright} 2007 Elsevier B.V. All rights reserved.},
author = {Heckman, James J. and Vytlacil, Edward J.},
doi = {10.1016/S1573-4412(07)06070-9},
file = {:home/stefan/Dropbox/Academia/Library/Heckman, Vytlacil{\_}2007{\_}Econometric Evaluation of Social Programs, Part I Causal Models, Structural Models and Econometric Policy Evaluat.pdf:pdf},
isbn = {9780444532008},
issn = {15734412},
journal = {Handbook of Econometrics},
keywords = {causal models,counterfactuals,identification,policy evaluation,policy invariance,structural models},
number = {SUPPL. PART B},
pages = {4779--4874},
title = {{Econometric Evaluation of Social Programs, Part I: Causal Models, Structural Models and Econometric Policy Evaluation}},
volume = {6},
year = {2007}
}
@article{Stock1994,
author = {Stock, James H},
file = {:home/stefan/Dropbox/Academia/Library/Stock{\_}1994{\_}Unit Roots, Structural Breaks and Trends.pdf:pdf},
journal = {Handbook of Econometrics},
title = {{Unit Roots, Structural Breaks and Trends}},
volume = {IV},
year = {1994}
}
@article{Hendry1984,
author = {Hendry, David F},
file = {:home/stefan/Dropbox/Academia/Library/Hendry{\_}1984{\_}Monte Carlo experimentation in econometrics.pdf:pdf},
journal = {Handbook of Econometrics},
number = {16},
title = {{Monte Carlo experimentation in econometrics}},
url = {papers3://publication/uuid/79DC8A89-AA4D-402B-9828-50D00BDD81D4},
volume = {2},
year = {1984}
}
@book{Covariance1983,
author = {Theil, Henri},
booktitle = {Handbook of Econometrics},
file = {:home/stefan/Dropbox/Academia/Library/Theil{\_}1983{\_}Linear algebra and Matrix Methods in Econometrics.pdf:pdf},
title = {{Linear algebra and Matrix Methods in Econometrics}},
year = {1983}
}
@article{Rothenberg1984,
author = {Rothenberg, Thomas J},
file = {:home/stefan/Dropbox/Academia/Library/Rothenberg{\_}1984{\_}Approximating the distributions of econometric estimators and test statistics BT - Handbook of Econometrics.pdf:pdf},
journal = {Handbook of Econometrics},
number = {15},
title = {{Approximating the distributions of econometric estimators and test statistics BT  - Handbook of Econometrics}},
url = {papers3://publication/uuid/1A69F7F5-ADF6-4FB4-BB3C-5538CDFF460E},
volume = {2},
year = {1984}
}
@article{Taylor1986a,
author = {Taylor, John B.},
file = {:home/stefan/Dropbox/Academia/Library/Taylor{\_}1986{\_}New Econometric Approaches To Stabilization.pdf:pdf},
journal = {Handbook of Econometrics},
pages = {1997--2055},
title = {{New Econometric Approaches To Stabilization}},
volume = {III},
year = {1986}
}
@article{Lau1986,
author = {Lau, Lawrence J},
file = {:home/stefan/Dropbox/Academia/Library/Lau{\_}1986{\_}Functional forms in econometric model building.pdf:pdf},
journal = {Handbook of Econometrics},
number = {26},
title = {{Functional forms in econometric model building}},
url = {papers3://publication/uuid/BE36BC64-52D3-4B22-981F-AD4F28D54E91},
volume = {3},
year = {1986}
}
@book{Sen1990,
author = {Judge, G and Bock, ME},
booktitle = {Handbook of Econometrics},
doi = {10.1007/978-3-662-25092-1_12},
file = {:home/stefan/Dropbox/Academia/Library/Judge, Bock{\_}1983{\_}Biased Estimation.pdf:pdf},
title = {{Biased Estimation}},
year = {1983}
}
@article{Hall1994,
abstract = {A brief account is given of the methodology and theory for the bootstrap . Methodology is developed in the context of the “equation” approach, which allows attention to be focussed on specific criteria for excellence, such as coverage error of a confidence interval or expected value of a ...},
author = {Hall, Peter},
file = {:home/stefan/Dropbox/Academia/Library/Hall{\_}1994{\_}Methodology and theory for the bootstrap.pdf:pdf},
journal = {Handbook of econometrics, Vol.$\backslash$ IV},
pages = {2341--2381},
title = {{Methodology and theory for the bootstrap}},
url = {http://www.ams.org/mathscinet-getitem?mr=MR1315974{\%}5Cnpapers2://publication/uuid/CB872896-209B-4224-90BF-359D420E601A},
volume = {2},
year = {1994}
}
@article{Zellner1983a,
abstract = {It would be hard to overstate the importance of Moira Roth's celebrated essay "The Aesthetic of Indifference, " published in Artforum in November, 1977. In the over twentyyears since Roth published it, the essay has continued to be cited in nearly every new work on Cage, Cunningham, Johns, Rauschenberg and their circle. 1 Though much has changed in the intervening years in both the discipline of art history and our state ofknowledge of the figures she critiqued, her attempt to define and historicize what she understood to be a new Cold War aesthetic sensibility in American art has shown remarkable longevity and unmatched explanatory force. 2 "Marcel Duchamp in America: A Self Ready-Made:' published only seven months earlier in Arts (May 1977), constituted a kind ofhistorical and thematic predecessor to the "Aesthetic of Indifference:' for she understood the practice of artistic indifference discussed in the later essay as originating in Duchamp-who was then taken up as a model by the group around John Cage. Together, the two 1977 essays set out a new approach to the history of art, one sensitive not only to questions of political valence, but to what had long been considered mere ephemera in the still-formalist critical context of the time-notably artistic personae, sexuality, and the social historical roots of identity.},
author = {Zellner, Arnold and Intriligator, Michael D and Covariance, Extensions and Soc, N S F Grant and Clements, Kenneth and Bank, Reserve and Intriligator, Michael D and Hausman, Jerry a and Katz, Jonathan D. and Amemiya, Takeshi and Leamer, E D W A R D E and Sen, Ashish and Srivastava, Muni and Phillips, P C B and Krasker, William S and Kuh, Edwin and Welsch, Roy E and Dreze, J H and Richard, J and Theil, Henri and Nls, Amemiya and Quandt, Richard E and Econometrics, I N and Theil, Henri and Zellner, Arnold and فاطمی, حسن and To, Preface and Handbook, T H E},
doi = {10.1016/s1573-4412(83)01004-1},
file = {:home/stefan/Dropbox/Academia/Library/Zellner et al.{\_}1983{\_}Bayesian Analysis of Simultaneous Equation Models.pdf:pdf},
isbn = {9780444861856},
issn = {0032-633X},
journal = {Handbook of Econometrics},
number = {3},
pages = {517--598},
title = {{Bayesian Analysis of Simultaneous Equation Models}},
url = {papers3://publication/uuid/1398833A-9CD6-4BD7-A198-CD26CE45ADFD{\%}0Apapers3://publication/uuid/E4A36CEE-9A8A-427F-97C6-966E6EC32F77{\%}0Ahttp://www.sciencedirect.com/science/article/pii/S1573441283010119{\%}5Cnpapers3://publication/uuid/0482BCC8-5981-4F4F-91D1-CA},
volume = {1},
year = {1983}
}
@article{Chow1984,
author = {Chow, Gregory C},
file = {:home/stefan/Dropbox/Academia/Library/Chow{\_}1984{\_}Random and changing coefficient models.pdf:pdf},
journal = {Handbook of Econometrics},
number = {21},
title = {{Random and changing coefficient models}},
url = {papers3://publication/uuid/3D005866-D5E1-4114-988A-710E8F936B25},
volume = {2},
year = {1984}
}
@book{Molinari2020,
abstract = {This chapter reviews the microeconometrics literature on partial identification, focusing on the developments of the last thirty years. The topics presented illustrate that the available data combined with credible maintained assumptions may yield much information about a parameter of interest, even if they do not reveal it exactly. Special attention is devoted to discussing the challenges associated with, and some of the solutions put forward to, (1) obtain a tractable characterization of the values for the parameters of interest which are observationally equivalent, given the available data and maintained assumptions; (2) estimate this set of values; (3) conduct test of hypotheses and make confidence statements. The chapter reviews advances in partial identification analysis both as applied to learning (functionals of) probability distributions that are well-defined in the absence of models, as well as to learning parameters that are well-defined only in the context of particular models. A simple organizing principle is highlighted: the source of the identification problem can often be traced to a collection of random variables that are consistent with the available data and maintained assumptions. This collection may be part of the observed data or be a model implication. In either case, it can be formalized as a random set. Random set theory is then used as a mathematical framework to unify a number of special results and produce a general methodology to carry out partial identification analysis.},
archivePrefix = {arXiv},
arxivId = {2004.11751},
author = {Molinari, Francesca},
booktitle = {Handbook of Econometrics},
doi = {10.1016/bs.hoe.2020.05.002},
eprint = {2004.11751},
file = {:home/stefan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Molinari - 2020 - Microeconometrics with partial identification.pdf:pdf},
isbn = {9780444636492},
issn = {15734412},
keywords = {Auction models,Computational methods,Criterion function approach,Discrete choice models,Incomplete data and models,Model misspecification,Moment inequalities,Partial identification,Random sets,Support function approach},
pages = {355--486},
publisher = {Elsevier B.V.},
title = {{Microeconometrics with partial identification}},
url = {https://doi.org/10.1016/bs.hoe.2020.05.002},
volume = {7},
year = {2020}
}
@article{Terasvitra1994,
author = {Ter{\"{a}}svitra, Timo and Tj{\o}stheim, Dag and Granger, Clive W.J.},
file = {:home/stefan/Dropbox/Academia/Library/Ter{\"{a}}svitra, Tj{\o}stheim, Granger{\_}1994{\_}Aspects of Modelling Nonlinear Time Series.pdf:pdf},
journal = {Handbook of Econometrics},
pages = {2917----2957},
title = {{Aspects of Modelling Nonlinear Time Series}},
volume = {4},
year = {1994}
}
@book{Hirano2020,
abstract = {Statistical decision rules map data into actions. Point estimators, inference procedures, and forecasting methods can be viewed as statistical decision rules. However, other types of rules are possible, such as rules for assigning individuals to treatments based on covariates, and methods for designing auctions. We discuss heuristics for constructing statistical decision rules, and survey results that characterize the properties of various classes of decision rules. Particular attention is paid to developing large-sample approximations to the distributions and associated risk properties of statistical decision rules.},
author = {Hirano, Keisuke and Porter, Jack R.},
booktitle = {Handbook of Econometrics},
doi = {10.1016/bs.hoe.2020.09.001},
file = {:home/stefan/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hirano, Porter - 2020 - Asymptotic analysis of statistical decision rules in econometrics⋆.pdf:pdf},
isbn = {9780444636492},
issn = {15734412},
keywords = {Limit experiments,Risk,Statistical decision theory,Treatment assignment rules},
pages = {283--354},
publisher = {Elsevier B.V.},
title = {{Asymptotic analysis of statistical decision rules in econometrics⋆}},
url = {https://doi.org/10.1016/bs.hoe.2020.09.001},
volume = {7},
year = {2020}
}
