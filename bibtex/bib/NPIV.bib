Automatically generated by Mendeley Desktop 1.19.8
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Material2011,
abstract = {The focus of this paper is the nonparametric estimation of an instrumental regression function ϕ defined by conditional moment restrictions that stem from a structural econometric model E[Y−ϕ(Z) ΙW]=0, and involve endogenous variables Y and Z and instruments W. The function ϕ is the solution of an ill-posed inverse problem and we propose an estimation procedure based on Tikhonov regularization. The paper analyzes identification and overidentification of this model, and presents asymptotic properties of the estimated nonparametric instrumental regression function. [ABSTRACT FROM AUTHOR]},
author = {Material, Econometrica Supplementary},
doi = {10.3982/ecta6539},
file = {:home/stefan/Dropbox/NPweakIV 2021/NPIV/dffr-ecta-appB.pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
number = {5},
pages = {1541--1565},
title = {{Nonparametric Instrumental Regression}},
volume = {79},
year = {2011}
}
@article{Darolles2011a,
abstract = {The focus of this paper is the nonparametric estimation of an instrumental regression function ϕ defined by conditional moment restrictions that stem from a structural econometric model E[Y−ϕ(Z) ΙW]=0, and involve endogenous variables Y and Z and instruments W. The function ϕ is the solution of an ill-posed inverse problem and we propose an estimation procedure based on Tikhonov regularization. The paper analyzes identification and overidentification of this model, and presents asymptotic properties of the estimated nonparametric instrumental regression function. [ABSTRACT FROM AUTHOR]},
author = {Darolles, S and Fan, Y and Florens, J P and Renault, E},
doi = {10.3982/ecta6539},
file = {:home/stefan/Dropbox/NPweakIV 2021/NPIV/dffr-ecta.pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
keywords = {Instrumental variables, integral equation, ill-pos},
number = {5},
pages = {1541--1565},
title = {{Nonparametric Instrumental Regression}},
volume = {79},
year = {2011}
}
@article{Chen2011,
abstract = {In this paper we clarify the relations between the existing sets of regularity conditions for convergence rates of nonparametric indirect regression (NPIR) and nonparametric instrumental variables (NPIV) regression models. We establish minimax risk lower bounds in mean integrated squared error loss for the NPIR and NPIV models under two basic regularity conditions: the approximation number and the link condition. We show that both a simple projection estimator for the NPIR model and a sieve minimum distance estimator for the NPIV model can achieve the minimax risk lower bounds and are rate optimal uniformly over a large class of structure functions, allowing for mildly ill-posed and severely ill-posed cases. {\textcopyright} Copyright Cambridge University Press 2011.},
archivePrefix = {arXiv},
arxivId = {0709.2003},
author = {Chen, Xiaohong and Reiss, Markus},
doi = {10.1017/S0266466610000381},
eprint = {0709.2003},
file = {:home/stefan/Dropbox/NPweakIV 2021/NPIV/Chen and Reiss 2011.pdf:pdf},
issn = {02664666},
journal = {Econometric Theory},
number = {3},
pages = {497--521},
title = {{On rate optimality for ill-posed inverse problems in econometrics}},
volume = {27},
year = {2011}
}
@article{Pouzo2017,
abstract = {We propose a general framework for regularization in M-estimation problems under time dependent (absolutely regular-mixing) data which encompasses many of the existing estimators. We derive non-asymptotic concentration bounds for the regularized M-estimator. Our results exhibit a variance-bias trade-off, with the variance term being governed by a novel measure of the complexity of the parameter set. We also show that the mixing structure affect the variance term by scaling the number of observations; depending on the decay rate of the mixing coefficients, this scaling can even affect the asymptotic behavior. Finally, we propose a data-driven method for choosing the tuning parameters of the regularized estimator which yield the same (up to constants) concentration bound as one that optimally balances the (squared) bias and variance terms. We illustrate the results with several canonical examples.},
archivePrefix = {arXiv},
arxivId = {1512.06290},
author = {Pouzo, Demian},
doi = {10.2139/ssrn.2857126},
eprint = {1512.06290},
file = {:home/stefan/Dropbox/NPweakIV 2021/adaptive methods/Pouzo 2016.pdf:pdf},
journal = {SSRN Electronic Journal},
title = {{On the Non-Asymptotic Properties of Regularized M-Estimators}},
year = {2017}
}
@article{Chen2018a,
abstract = {This paper makes several important contributions to the literature about nonparametric instrumental variables (NPIV) estimation and inference on a structural function {\$}h{\_}0{\$} and its functionals. First, we derive sup-norm convergence rates for computationally simple sieve NPIV (series 2SLS) estimators of {\$}h{\_}0{\$} and its derivatives. Second, we derive a lower bound that describes the best possible (minimax) sup-norm rates of estimating {\$}h{\_}0{\$} and its derivatives, and show that the sieve NPIV estimator can attain the minimax rates when {\$}h{\_}0{\$} is approximated via a spline or wavelet sieve. Our optimal sup-norm rates surprisingly coincide with the optimal root-mean-squared rates for severely ill-posed problems, and are only a logarithmic factor slower than the optimal root-mean-squared rates for mildly ill-posed problems. Third, we use our sup-norm rates to establish the uniform Gaussian process strong approximations and the score bootstrap uniform confidence bands (UCBs) for collections of nonlinear functionals of {\$}h{\_}0{\$} under primitive conditions, allowing for mildly and severely ill-posed problems. Fourth, as applications, we obtain the first asymptotic pointwise and uniform inference results for plug-in sieve t-statistics of exact consumer surplus (CS) and deadweight loss (DL) welfare functionals under low-level conditions when demand is estimated via sieve NPIV. Empiricists could read our real data application of UCBs for exact CS and DL functionals of gasoline demand that reveals interesting patterns and is applicable to other markets.},
archivePrefix = {arXiv},
arxivId = {1508.03365},
author = {Chen, Xiaohong and Christensen, Timothy M.},
doi = {10.3982/qe722},
eprint = {1508.03365},
file = {:home/stefan/Dropbox/NPweakIV 2021/NPIV/Chen and Christensen (QE, supp).pdf:pdf},
issn = {17597331},
journal = {Quantitative Economics},
number = {1},
pages = {39--84},
title = {{Optimal sup-norm rates and uniform inference on nonlinear functionals of nonparametric IV regression}},
volume = {9},
year = {2018}
}
@article{Chen2015,
abstract = {We show that spline and wavelet series regression estimators for weakly dependent regressors attain the optimal uniform (i.e. sup-norm) convergence rate (n/logn)-p/(2p+d) of Stone (1982), where d is the number of regressors and p is the smoothness of the regression function. The optimal rate is achieved even for heavy-tailed martingale difference errors with finite (2+(d/p))th absolute moment for d/p{\textless}2. We also establish the asymptotic normality of t statistics for possibly nonlinear, irregular functionals of the conditional mean function under weak conditions. The results are proved by deriving a new exponential inequality for sums of weakly dependent random matrices, which is of independent interest.},
archivePrefix = {arXiv},
arxivId = {1412.6020},
author = {Chen, Xiaohong and Christensen, Timothy M.},
doi = {10.1016/j.jeconom.2015.03.010},
eprint = {1412.6020},
file = {:home/stefan/Dropbox/NPweakIV 2021/NPIV/Chen and Christensen (2015, JoE).pdf:pdf},
issn = {18726895},
journal = {Journal of Econometrics},
keywords = {Nonparametric series regression,Optimal uniform convergence rates,Random matrices,Sieve t statistics,Splines,Wavelets (Nonlinear) Irregular functionals,Weak dependence},
number = {2},
pages = {447--465},
publisher = {Elsevier B.V.},
title = {{Optimal uniform convergence rates and asymptotic normality for series estimators under weak dependence and weak conditions}},
url = {http://dx.doi.org/10.1016/j.jeconom.2015.03.010},
volume = {188},
year = {2015}
}
@article{Chen2013,
abstract = {We study the problem of nonparametric regression when the regressor is endogenous, which is an important nonparametric instrumental variables (NPIV) regression in econometrics and a difficult ill-posed inverse problem with unknown operator in statistics. We first establish a general upper bound on the sup-norm (uniform) convergence rate of a sieve estimator, allowing for endogenous regressors and weakly dependent data. This result leads to the optimal sup-norm convergence rates for spline and wavelet least squares regression estimators under weakly dependent data and heavy-tailed error terms. This upper bound also yields the sup-norm convergence rates for sieve NPIV estimators under i.i.d. data: the rates coincide with the known optimal L{\^{}}2-norm rates for severely ill-posed problems, and are power of log(n) slower than the optimal L{\^{}}2-norm rates for mildly ill-posed problems. We then establish the minimax risk lower bound in sup-norm loss, which coincides with our upper bounds on sup-norm rates for the spline and wavelet sieve NPIV estimators. This sup-norm rate optimality provides another justification for the wide application of sieve NPIV estimators. Useful results on weakly-dependent random matrices are also provided.},
archivePrefix = {arXiv},
arxivId = {1311.0412},
author = {Chen, Xiaohong and Christensen, Timothy M.},
doi = {10.2139/ssrn.2349684},
eprint = {1311.0412},
file = {:home/stefan/Dropbox/NPweakIV 2021/NPIV/Chen and Christensen (QE).pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
keywords = {Series two-stage least squares,optimal sup-norm c},
pages = {39--84},
title = {{Optimal Uniform Convergence Rates for Sieve Nonparametric Instrumental Variables Regression}},
volume = {9},
year = {2013}
}
@article{DeMol2009,
abstract = {Within the framework of statistical learning theory we analyze in detail the so-called elastic-net regularization scheme proposed by Zou and Hastie [H. Zou, T. Hastie, Regularization and variable selection via the elastic net, J. R. Stat. Soc. Ser. B, 67(2) (2005) 301-320] for the selection of groups of correlated variables. To investigate the statistical properties of this scheme and in particular its consistency properties, we set up a suitable mathematical framework. Our setting is random-design regression where we allow the response variable to be vector-valued and we consider prediction functions which are linear combinations of elements (features) in an infinite-dimensional dictionary. Under the assumption that the regression function admits a sparse representation on the dictionary, we prove that there exists a particular "elastic-net representation" of the regression function such that, if the number of data increases, the elastic-net estimator is consistent not only for prediction but also for variable/feature selection. Our results include finite-sample bounds and an adaptive scheme to select the regularization parameter. Moreover, using convex analysis tools, we derive an iterative thresholding algorithm for computing the elastic-net solution which is different from the optimization procedure originally proposed in the above-cited work. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {0807.3423},
author = {{De Mol}, Christine and {De Vito}, Ernesto and Rosasco, Lorenzo},
doi = {10.1016/j.jco.2009.01.002},
eprint = {0807.3423},
file = {:home/stefan/Dropbox/NPweakIV 2021/other cool stuffs/elastic net regularization.pdf:pdf},
issn = {10902708},
journal = {Journal of Complexity},
keywords = {Elastic net,Learning,Regularization,Sparsity},
number = {2},
pages = {201--230},
publisher = {Elsevier Inc.},
title = {{Elastic-net regularization in learning theory}},
url = {http://dx.doi.org/10.1016/j.jco.2009.01.002},
volume = {25},
year = {2009}
}
@article{Jansson2017,
abstract = {We present a general framework for studying regularized estimators; such estimators are pervasive in estimation problems wherein “plug-in” type estimators are either ill-defined or ill-behaved. Within this framework, we derive, under primitive conditions, consistency and a generalization of the asymptotic linearity property. We also provide data-driven methods for choosing tuning parameters that, under some conditions, achieve the aforementioned properties. We illustrate the scope of our approach by studying a wide range of applications, revisiting known results and deriving new ones.},
archivePrefix = {arXiv},
arxivId = {1712.07248},
author = {Jansson, Michael and Pouzo, Demian},
eprint = {1712.07248},
file = {:home/stefan/Dropbox/NPweakIV 2021/adaptive methods/Jansson and Pouzo 2017.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--79},
title = {{Towards a general large sample theory for regularized estimators}},
year = {2017}
}
@article{Lepskii2001,
author = {Lepskii, O.V.},
doi = {10.2307/3318602},
file = {:home/stefan/Dropbox/NPweakIV 2021/adaptive methods/Lepskii (1987).pdf:pdf},
issn = {13507265},
journal = {Theory Probability Applications},
keywords = {Adaptive methods},
number = {3},
pages = {454--466},
title = {{On the problem of local adaptive estimation in Gaussian white noise}},
volume = {35},
year = {2001}
}
@article{Breunig2016,
abstract = {We consider the problem of estimating the value l($\phi$) of a linear functional, where the structural function $\phi$ models a nonparametric relationship in presence of instrumental variables. We propose a plug-in estimator which is based on a dimension reduction technique and additional thresholding. It is shown that this estimator is consistent and can attain the minimax optimal rate of convergence under additional regularity conditions. This, however, requires an optimal choice of the dimension parameter m depending on certain characteristics of the structural function $\phi$ and the joint distribution of the regressor and the instrument, which are unknown in practice. We propose a fully data driven choice of m which combines model selection and Lepski's method. We show that the adaptive estimator attains the optimal rate of convergence up to a logarithmic factor. The theory in this paper is illustrated by considering classical smoothness assumptions and we discuss examples such as pointwise estimation or estimation of averages of the structural function $\phi$.},
author = {Breunig, Christoph and Johannes, Jan},
doi = {10.1017/S0266466614000966},
file = {:home/stefan/Dropbox/NPweakIV 2021/adaptive methods/Breunig and Johannes (2016).pdf:pdf},
issn = {14694360},
journal = {Econometric Theory},
number = {3},
pages = {612--654},
title = {{Adaptive estimation of functionals in nonparametric instrumental regression}},
volume = {32},
year = {2016}
}
@article{Han2020,
abstract = { This paper analyzes the problem of weak instruments on identification, estimation, and inference in a simple nonparametric model of a triangular system. The paper derives a necessary and sufficient rank condition for identification, based on which weak identification is established. Then nonparametric weak instruments are defined as a sequence of reduced‐form functions where the associated rank shrinks to zero. The problem of weak instruments is characterized as concurvity , which motivates the introduction of a regularization scheme. The paper proposes a penalized series estimation method to alleviate the effects of weak instruments and shows that it achieves desirable asymptotic properties. A data‐driven procedure is proposed for the choice of the penalization parameter. The findings of this paper provide useful implications for empirical work. To illustrate them, Monte Carlo results are presented and an empirical example is given in which the effect of class size on test scores is estimated nonparametrically. },
author = {Han, Sukjin},
doi = {10.3982/qe975},
file = {:home/stefan/Dropbox/NPweakIV 2021/weak IV in triangular models/Han{\_}2020supp.pdf:pdf},
issn = {1759-7323},
journal = {Quantitative Economics},
number = {1},
pages = {161--202},
title = {{Nonparametric estimation of triangular simultaneous equations models under weak identification}},
volume = {11},
year = {2020}
}
@unpublished{NeweyPowell2002,
author = {Newey, Whitney K. and Powell, James L.},
file = {:home/stefan/Downloads/npiv.pdf:pdf},
title = {{Instrumental Variable Estimation of Nonparametric Models}},
year = {2002}
}
@article{Freyberger2017,
abstract = {This paper provides a first test for the identification condition in a nonparametric instrumental variable model, known as completeness, by linking the outcome of the test to consistency of an estimator. In particular, I show that uniformly over all distributions for which the test rejects with probability bounded away from 0, an estimator of the structural function is consistent. This is the case for a large class of complete distributions as well as certain sequences of incomplete distributions. As a byproduct of this result, the paper makes two additional contributions. First, I present a definition of weak instruments in the nonparametric instrumental variable model, which is equivalent to the failure of a restricted version of completeness. Second, I show that the null hypothesis of weak instruments, and thus failure of a restricted version of completeness, is testable and I provide a test statistic  and a bootstrap procedure to obtain the critical values. Finally, I demonstrate the finite sample properties of the tests and the estimator in Monte Carlo simulations.},
author = {Freyberger, Joachim},
doi = {10.3982/ecta13304},
file = {:home/stefan/Dropbox/NPweakIV 2021/testability of completeness/Freyberger (2017).pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
keywords = {Completeness, testing, consistency, instrumental v},
number = {5},
pages = {1629--1644},
title = {{On Completeness and Consistency in Nonparametric Instrumental Variable Models}},
volume = {85},
year = {2017}
}
@article{Babii2017,
abstract = {This paper studies non-identified ill-posed inverse models with estimated operator. Leading examples are the nonparametric IV regression and the functional linear IV regression. We argue that identification of infinite-dimensional parameters is less crucial than identification of finite-dimensional parameters. We show that in the case of identification failures, a very general family of continuously-regularized estimators is consistent for the best approximation of the parameter of interest and obtain L2 and L∞ finite-sample risk bounds. This class includes Tikhonov, iterated Tikhonov, spectral cut-off, and Landweber-Fridman as special cases. We show that in many cases the best approximation coincides with the structural parameter and can be a useful and tractable object to infer relation between structural variables otherwise. Unlike in the identified case, estimation of the operator may have a non-negligible impact on the estimation accuracy and inference. We develop inferential methods for linear functionals in non-identified models as well as honest uniform confidence sets for the best approximation. Lastly, we demonstrate the discontinuity in the asymptotic distribution for extreme cases of identification failures where we observe a degenerate U-statistics asymptotics.},
author = {Babii, Andrii and Florens, Jean Pierre},
file = {:home/stefan/Dropbox/NPweakIV 2021/NPIV without completeness/Babii {\&} Florens (2020) - Is completeness necessary.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {alex belloni,c14,c26,christoph breunig,eric,federico bugni,func-,irene botosaru,jel classifications,nonidentified linear models,nonparametric iv regression,tikhonov regularization,tional linear iv regression,we are grateful to,weak identification},
title = {{Is completeness necessary? Estimation in nonidentified linear models}},
year = {2017}
}
@article{Chen2018,
abstract = {This paper makes several important contributions to the literature about nonparametric instrumental variables (NPIV) estimation and inference on a structural function {\$}h{\_}0{\$} and its functionals. First, we derive sup-norm convergence rates for computationally simple sieve NPIV (series 2SLS) estimators of {\$}h{\_}0{\$} and its derivatives. Second, we derive a lower bound that describes the best possible (minimax) sup-norm rates of estimating {\$}h{\_}0{\$} and its derivatives, and show that the sieve NPIV estimator can attain the minimax rates when {\$}h{\_}0{\$} is approximated via a spline or wavelet sieve. Our optimal sup-norm rates surprisingly coincide with the optimal root-mean-squared rates for severely ill-posed problems, and are only a logarithmic factor slower than the optimal root-mean-squared rates for mildly ill-posed problems. Third, we use our sup-norm rates to establish the uniform Gaussian process strong approximations and the score bootstrap uniform confidence bands (UCBs) for collections of nonlinear functionals of {\$}h{\_}0{\$} under primitive conditions, allowing for mildly and severely ill-posed problems. Fourth, as applications, we obtain the first asymptotic pointwise and uniform inference results for plug-in sieve t-statistics of exact consumer surplus (CS) and deadweight loss (DL) welfare functionals under low-level conditions when demand is estimated via sieve NPIV. Empiricists could read our real data application of UCBs for exact CS and DL functionals of gasoline demand that reveals interesting patterns and is applicable to other markets.},
archivePrefix = {arXiv},
arxivId = {1508.03365},
author = {Chen, Xiaohong and Christensen, Timothy M.},
doi = {10.3982/qe722},
eprint = {1508.03365},
file = {:home/stefan/Dropbox/NPweakIV 2021/NPIV/Chen and Christensen (QE, supp2).pdf:pdf},
issn = {17597331},
journal = {Quantitative Economics},
number = {1},
pages = {39--84},
title = {{Optimal sup-norm rates and uniform inference on nonlinear functionals of nonparametric IV regression}},
volume = {9},
year = {2018}
}
@article{Canay2013,
abstract = {This paper examines three distinct hypothesis testing problems that arise in the context of identification of some nonparametric models with endogeneity. The first hypothesis testing problem we study concerns testing necessary conditions for identification in some nonparametric models with endogeneity involving mean independence restrictions. These conditions are typically referred to as completeness conditions. The second and third hypothesis testing problems we examine concern testing for identification directly in some nonparametric models with endogeneity involving quantile independence restrictions. For each of these hypothesis testing problems, we provide conditions under which any test will have power no greater than size against any alternative. In this sense, we conclude that no nontrivial tests for these hypothesis testing problems exist.},
author = {Canay, Ivan A},
doi = {10.3982/ecta10851},
file = {:home/stefan/Dropbox/NPweakIV 2021/testability of completeness/Canay et al. (2013).pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
number = {6},
pages = {2535--2559},
title = {{On the Testability of Identification in Some Nonparametric Models With Endogeneity}},
volume = {81},
year = {2013}
}
@article{Chen2013a,
abstract = {We study the problem of nonparametric regression when the regressor is endogenous, which is an important nonparametric instrumental variables (NPIV) regression in econometrics and a difficult ill-posed inverse problem with unknown operator in statistics. We first establish a general upper bound on the sup-norm (uniform) convergence rate of a sieve estimator, allowing for endogenous regressors and weakly dependent data. This result leads to the optimal sup-norm convergence rates for spline and wavelet least squares regression estimators under weakly dependent data and heavy-tailed error terms. This upper bound also yields the sup-norm convergence rates for sieve NPIV estimators under i.i.d. data: the rates coincide with the known optimal L{\^{}}2-norm rates for severely ill-posed problems, and are power of log(n) slower than the optimal L{\^{}}2-norm rates for mildly ill-posed problems. We then establish the minimax risk lower bound in sup-norm loss, which coincides with our upper bounds on sup-norm rates for the spline and wavelet sieve NPIV estimators. This sup-norm rate optimality provides another justification for the wide application of sieve NPIV estimators. Useful results on weakly-dependent random matrices are also provided.},
archivePrefix = {arXiv},
arxivId = {1311.0412},
author = {Chen, Xiaohong and Christensen, Timothy M.},
doi = {10.2139/ssrn.2349684},
eprint = {1311.0412},
file = {:home/stefan/Dropbox/NPweakIV 2021/adaptive methods/Chen and Christensen (2015).pdf:pdf},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
number = {1923},
title = {{Optimal Uniform Convergence Rates for Sieve Nonparametric Instrumental Variables Regression}},
year = {2013}
}
@article{Chen2015a,
abstract = {This paper makes several contributions to the literature on the important yet difficult problem of estimating functions nonparametrically using instrumental variables. First, we derive the minimax optimal sup-norm convergence rates for nonparametric instrumental variables (NPIV) estimation of the structural function h{\_}0 and its derivatives. Second, we show that a computationally simple sieve NPIV estimator can attain the optimal sup-norm rates for h{\_}0 and its derivatives when h{\_}0 is approximated via a spline or wavelet sieve. Our optimal sup-norm rates surprisingly coincide with the optimal L{\^{}}2-norm rates for severely ill-posed problems, and are only up to a [log(n)]{\^{}}epsilon (with epsilon {\textless} 1/2) factor slower than the optimal L{\^{}}2-norm rates for mildly ill-posed problems. Third, we introduce a novel data-driven procedure for choosing the sieve dimension optimally. Our data-driven procedure is sup-norm rate-adaptive: the resulting estimator of h{\_}0 and its derivatives converge at their optimal sup-norm rates even though the smoothness of h{\_}0 and the degree of ill-posedness of the NPIV model are unknown. Finally, we present two non-trivial applications of the sup-norm rates to inference on nonlinear functionals of h{\_}0 under low-level conditions. The first is to derive the asymptotic normality of sieve t-statistics for exact consumer surplus and deadweight loss functionals in nonparametric demand estimation when prices, and possibly incomes, are endogenous. The second is to establish the validity of a sieve score bootstrap for constructing asymptotically exact uniform confidence bands for collections of nonlinear functionals of h{\_}0. Both applications provide new and useful tools for empirical research on nonparametric models with endogeneity.},
author = {Chen, Xiaohong and Christensen, Timothy M.},
doi = {10.2139/ssrn.2588495},
file = {:home/stefan/Dropbox/NPweakIV 2021/adaptive methods/Chen and Christensen (2015), supp.pdf:pdf},
journal = {SSRN Electronic Journal},
number = {1993},
pages = {1--54},
title = {{Optimal Sup-Norm Rates, Adaptivity and Inference in Nonparametric Instrumental Variables Estimation}},
volume = {0},
year = {2015}
}
@article{Santos2012,
abstract = {This paper develops methods for hypothesis testing in a nonparametric instrumental variables setting within a partial identification framework. We construct and derive the asymptotic distribution of a test statistic for the hypothesis that at least one element of the identified set satisfies a conjectured restriction. The same test statistic can be employed under identification, in which case the hypothesis is whether the true model satisfies the posited property. An almost sure consistent bootstrap procedure is provided for obtaining critical values. Possible applications include testing for semiparametric specifications as well as building confidence regions for certain functionals on the identified set. As an illustration we obtain confidence intervals for the level and slope of Brazilian fuel Engel curves. A Monte Carlo study examines finite sample performance. [ABSTRACT FROM AUTHOR]},
author = {Santos, Andres},
doi = {10.3982/ecta7493},
file = {:home/stefan/Dropbox/NPweakIV 2021/NPIV without completeness/Santos (2012).pdf:pdf},
issn = {0012-9682},
journal = {Econometrica},
keywords = {Instrumental variables, partial identification, bo},
number = {1},
pages = {213--275},
title = {{Inference in Nonparametric Instrumental Variables With Partial Identification}},
volume = {80},
year = {2012}
}
@article{Pereverzev2005,
abstract = {We study the possibility of using the structure of the regularization error for a posteriori choice of the regularization parameter. As a result, a rather general form of a selection criterion is proposed, and its relation to the heuristical quasi-optimality principle of Tikhonov and Glasko [Z. Vychisl. Mat. Mat. Fiz., 4 (1964 564-571] and to an adaptation scheme proposed in a statistical context by Lepskii [Theory Probab. Appl., 36 (1990 454-466] is discussed. The advantages of the proposed criterion are illustrated by using such examples as self-regularization of the trapezoidal rule for noisy Abel-type integral equations, Lavrentiev regularization for nonlinear ill-posed problems, and an inverse problem of the two-dimensional profile reconstruction. {\textcopyright} 2008 Society for Industrial and Applied Mathematics.},
author = {Pereverzev, Sergei and Schock, Eberhard},
doi = {10.1137/S0036142903433819},
file = {:home/stefan/Dropbox/NPweakIV 2021/adaptive methods/Pereverzev and Schock (2005).pdf:pdf},
issn = {00361429},
journal = {SIAM Journal on Numerical Analysis},
keywords = {Abel integral equations,Inverse problems in Banach spaces,Lavrentiev regularization for equations with monot,Parameter choice,Profile reconstruction,Scattering},
number = {5},
pages = {2060--2076},
title = {{On the adaptive selection of the parameter in regularization of ill-posed problems}},
volume = {43},
year = {2005}
}
